---
title: "A One-to-Many Conditional Generative Adversarial Network Framework for Multiple Image-to-Image Translations"
collection: publications
permalink: /publication/2018-04-30-paper1
excerpt: 'This paper is about image-to-image translation on design project pictures crawl from Behance.net.'
date: 2018-04-30
venue: 'Multimedia Tools & Applications'
paperurl: 'https://link.springer.com/content/pdf/10.1007%2Fs11042-018-5968-7.pdf'
citation: 'Chai, C., Liao, J., Zou, N., & Sun, L. (2018). "A One-to-Many Conditional Generative Adversarial Network Framework for Multiple Image-to-Image Translations." <i>Multimedia Tools & Applications</i>. 77(11).'
---
This paper is about image-to-image translation on design project pictures crawl from Behance.net.

[Download](https://link.springer.com/content/pdf/10.1007%2Fs11042-018-5968-7.pdf)

## Abstract
Image-to-Image translation was proposed as a general form of many image learning problems. While generative adversarial networks were successfully applied on many image-to-image translations, many models were limited to specific translation tasks and were difficult to satisfy practical needs. In this work, we introduce a One-to-Many conditional generative adversarial network, which could learn from heterogeneous sources of images. This is achieved by training multiple generators against a discriminator in synthesized learning way. This framework supports generative models to generate images in each source, so output images follow corresponding target patterns. Two implementations, hybrid fake and cascading learning, of the synthesized adversarial training scheme are also proposed, and experimented on two benchmark datasets, UTZap50K and MVOD5K, as well as a new high-quality dataset BehTex7K. We consider five challenging image-to-image translation tasks: edges-to-photo, edges-to-similar-photo translation on UTZap50K, cross-view translation on MVOD5K, and grey-to-color, grey-to-Oil-Paint on BehTex7K. We show that both implementations are able to faithfully translate from an image to another image in edges-to-photo, edges-to-similar-photo, grey-to-color, and grey-to-Oil-Paint translation tasks. The quality of output images in cross-view translation need to be further boosted.
